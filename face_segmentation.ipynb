{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe91f74ddcfa459997f52627d47724bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_987fa20a059a40cd8a346d570db136f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49174c357a1949b7a0c729e5ce55e237",
              "IPY_MODEL_8b48113d3d50454db75f25eadf216c92"
            ]
          }
        },
        "987fa20a059a40cd8a346d570db136f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49174c357a1949b7a0c729e5ce55e237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a820fe16fccf495cb9f064d1d4296cbd",
            "_dom_classes": [],
            "description": "Processing Bianca_Lawson (1 image(s)): 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2622,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2622,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beb1e1bf80ed47c2866b88c2b40e07d1"
          }
        },
        "8b48113d3d50454db75f25eadf216c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f699e63fa1334cc784452c1637fde8e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2622/2622 [1:19:14&lt;00:00,  1.81s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aecfdf7081aa4cec930cbfab15806fc1"
          }
        },
        "a820fe16fccf495cb9f064d1d4296cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beb1e1bf80ed47c2866b88c2b40e07d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f699e63fa1334cc784452c1637fde8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aecfdf7081aa4cec930cbfab15806fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leinadh/PeruvianImageGenerator/blob/master/face_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opYS4xCynqx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12a56184-eef5-496c-8a83-5d562fa9ef44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L-D644Q_liL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -zxvf '/content/drive/My Drive/Made with ML/datasets/vgg_face_dataset.tar.gz'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_Sud4__4pL",
        "colab_type": "text"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq4ivZdV_6Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r PeruvianImageGenerator/ # to delete file cloned before"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-KboMs_Flpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "b359640a-108f-4469-ce5c-3fdc1936bc2c"
      },
      "source": [
        "!git clone https://github.com/Leinadh/PeruvianImageGenerator.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PeruvianImageGenerator'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 14395 (delta 0), reused 2 (delta 0), pack-reused 14391\u001b[K\n",
            "Receiving objects: 100% (14395/14395), 595.15 MiB | 18.10 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "Checking out files: 100% (14324/14324), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGlVyQpEFoDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PeruvianImageGenerator.scripts.download_faces as dlf\n",
        "import PeruvianImageGenerator.scripts.plot_utils as plot_utils"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQioj4yhFqJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "fe91f74ddcfa459997f52627d47724bc",
            "987fa20a059a40cd8a346d570db136f0",
            "49174c357a1949b7a0c729e5ce55e237",
            "8b48113d3d50454db75f25eadf216c92",
            "a820fe16fccf495cb9f064d1d4296cbd",
            "beb1e1bf80ed47c2866b88c2b40e07d1",
            "f699e63fa1334cc784452c1637fde8e0",
            "aecfdf7081aa4cec930cbfab15806fc1"
          ]
        },
        "outputId": "8cd533d7-261d-4dc2-989f-f5c18dac459f"
      },
      "source": [
        "data_path = '/content/PeruvianImageGenerator/datasets/face_datasets/vgg_face_dataset/files'\n",
        "target_path='/content/tmp/face_images/'\n",
        "# dlf.parse_data(data_path, 1000, 1, target_path, 10, 40)\n",
        "dlf.download_vgg_images(data_path, num_people=2622, num_images=1, target_path=target_path,\n",
        "                        offset_x_percent=25, offset_top_percent=65,\n",
        "                        offset_bottom_percent=12, min_pose=3, min_score=0,\n",
        "                        curation=False, formats_allowed=['jpg', 'jpeg'], from_notebook=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe91f74ddcfa459997f52627d47724bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2622.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading time: 73.9 min\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LvZTd4_3d1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "e96e0f0c-bb57-48d9-f59d-37c3793563cb"
      },
      "source": [
        "dlf.clean_corrupt_files(target_path, formats_allowed=['jpg', 'jpeg'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing corrupt file: Dean_Martin_1.jpg\n",
            "Removing corrupt file: Jim_Sturgess_1.jpg\n",
            "Removing corrupt file: Diana_Rigg_1.jpg\n",
            "Removing corrupt file: Ida_Lupino_1.jpg\n",
            "Removing corrupt file: Alexander_Siddig_1.jpg\n",
            "Removing corrupt file: Gloria_Reuben_1.jpg\n",
            "Removing corrupt file: Abel_Ferrara_1.jpg\n",
            "Removing corrupt file: James_Stewart_1.jpg\n",
            "Removing corrupt file: Marcello_Mastroianni_1.jpg\n",
            "Removing corrupt file: Dwight_Schultz_1.jpg\n",
            "Removing corrupt file: William_Devane_1.jpg\n",
            "Removing corrupt file: Christina_Moore_1.jpg\n",
            "Removing corrupt file: Andy_Richter_1.jpg\n",
            "Removing corrupt file: Lee_Marvin_1.jpg\n",
            "Removing corrupt file: John_Amos_1.jpg\n",
            "Removing corrupt file: Fred_Astaire_1.jpg\n",
            "Removing corrupt file: Jane_Campion_1.jpg\n",
            "Removing corrupt file: Adam_Rodriguez_1.jpg\n",
            "Removing corrupt file: Jeffrey_Hunter_1.jpg\n",
            "Removing corrupt file: Joey_Heatherton_1.jpg\n",
            "Removing corrupt file: Sal_Mineo_1.jpg\n",
            "Removing corrupt file: Jack_Lemmon_1.jpg\n",
            "Removing corrupt file: Grace_Zabriskie_1.jpg\n",
            "Removing corrupt file: Alan_Tudyk_1.jpg\n",
            "Removing corrupt file: Seth_Green_1.jpg\n",
            "Removing corrupt file: Russell_Peters_1.jpg\n",
            "Removing corrupt file: Suzanne_Pleshette_1.jpg\n",
            "Removing corrupt file: Dorothy_Malone_1.jpg\n",
            "Removing corrupt file: Claude_Rains_1.jpg\n",
            "Removing corrupt file: Marlene_Dietrich_1.jpg\n",
            "Removing corrupt file: Olivia_de_Havilland_1.jpg\n",
            "Removing corrupt file: Ty_Olsson_1.jpg\n",
            "Removing corrupt file: Myrna_Loy_1.jpg\n",
            "\n",
            "33 file(s) removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkw6PmAlguBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !zip -r /content/face_images.zip tmp/face_images"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5p1yJ4Z4TkV",
        "colab_type": "text"
      },
      "source": [
        "# Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAqWhXVUS7eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysA1SVe_VKgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See random image\n",
        "\n",
        "path = '/content/tmp'\n",
        "img_size = 64\n",
        "batch_size = 64\n",
        "# Especificamos la función de preprocesamiento\n",
        "train_datagen = ImageDataGenerator()\n",
        "train_generator = train_datagen.flow_from_directory(path, target_size=(img_size, img_size), batch_size=batch_size, subset='training')\n",
        "# Veamos alguna de las imágenes\n",
        "random_img = np.random.choice(train_generator.filenames)\n",
        "print(random_img)\n",
        "Image.open(path + '/' + random_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXtqKtVyVbmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras-segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRz0e7mHbHjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_segmentation.pretrained import pspnet_101_voc12\n",
        "import cv2\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "from time import time"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXDJonGhQFW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_background(img_mask, img1, output_path, output_file):\n",
        "\n",
        "  seg_gray = cv2.cvtColor(img_mask, cv2.COLOR_BGR2GRAY)\n",
        "  _,bg_mask = cv2.threshold(seg_gray, 0, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)\n",
        "\n",
        "  ## convert mask to 3-channels\n",
        "  bg_mask = cv2.cvtColor(bg_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "  ## cv2.bitwise_and to extract the region\n",
        "  bg = cv2.bitwise_or(img1, bg_mask)\n",
        "\n",
        "  ## save \n",
        "  cv2.imwrite(output_path + output_file, bg)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIx_EIW2F4C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove background\n",
        "path = '/content/tmp/face_images/'\n",
        "mask_path = '/content/tmp/masks/'\n",
        "output_path = '/content/face_images_wo_bg/'\n",
        "\n",
        "if not os.path.exists(mask_path):\n",
        "  os.makedirs(mask_path)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "\n",
        "model = pspnet_101_voc12() # load the pretrained model trained on Pascal VOC 2012 dataset\n",
        "\n",
        "start = time()\n",
        "for filename in tqdm(os.listdir(path)):\n",
        "  # filename = filename.split('/')[1] \n",
        "  mask_file = filename[:-4] + \"_mask.png\"\n",
        "  output_file = filename[:-4] + \"_wo_bg.jpg\"\n",
        "\n",
        "\n",
        "  out = model.predict_segmentation(\n",
        "    inp= path + filename,\n",
        "    out_fname= mask_path + mask_file\n",
        "  )\n",
        "  \n",
        "  img_mask = cv2.imread(mask_path + mask_file)\n",
        "  img1 = cv2.imread(path + filename) #READ BGR\n",
        "\n",
        "  remove_background(img_mask, img1, output_path, output_file)\n",
        "end = time()\n",
        "print(f'Processing time: {round((end-start)/60, 2)} min\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHHpQ_YO5yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r -q /content/face_images_wo_bg.zip face_images_wo_bg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmmhkHtfIskA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/face_images_wo_bg.zip \"/content/drive/My Drive/Made with ML/datasets/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}